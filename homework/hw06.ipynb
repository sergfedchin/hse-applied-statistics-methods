{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.10.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "from scipy.optimize import minimize, newton\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections.abc import Iterable, Callable\n",
    "import os, sys\n",
    "practice_dir = os.path.join(os.path.dirname(os.path.abspath('')), 'practice')\n",
    "if not practice_dir in sys.path:\n",
    "    sys.path.append(practice_dir)\n",
    "from utils import generate_n_random_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYTICAL_EXPECTATION = 0\n",
    "DISTROS = [\"Uniform[-1, 1]\", \"Norm(0, 1)\", \"2xUniform[-1, 1]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache\n",
    "def norm_quantile(p: float, loc: float = 0, scale: float = 1) -> float:\n",
    "    return sps.norm.ppf(p, loc=loc, scale=scale)\n",
    "\n",
    "@lru_cache\n",
    "def student_quantile(p: float, n: int) -> float:\n",
    "    return sps.t.ppf(p, n)\n",
    "\n",
    "@lru_cache\n",
    "def chi_squared_quantile(p: float, n: int) -> float:\n",
    "    return sps.chi2.ppf(p, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Реализуем методы для оценки погрешности, наследуемой результатами статистической обработки данных от неопределенности исходных обрабатываемых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раннее рассмотренные функции подсчёта доверительного интервала для матождиания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_confidence_interval_1(sample: Iterable,\n",
    "                                      confidence_probability: float,\n",
    "                                      sigma_squared: float) -> tuple[float, float]:\n",
    "    n = len(sample)\n",
    "    term = norm_quantile((1 + confidence_probability) / 2) * math.sqrt(sigma_squared / n)\n",
    "    x_mean = np.mean(sample)\n",
    "    return (x_mean - term, x_mean + term)\n",
    "\n",
    "\n",
    "def sigma_squared_estimate(sample: list) -> float:\n",
    "    x_mean = np.mean(sample)\n",
    "    return sum([pow(xi - x_mean, 2) for xi in sample]) / (len(sample) - 1)\n",
    "\n",
    "def expectation_confidence_interval_2(sample: Iterable,\n",
    "                                      confidence_probability: float) -> tuple[float, float]:\n",
    "    n = len(sample)\n",
    "    term = student_quantile((1 + confidence_probability) / 2, n - 1) * math.sqrt(sigma_squared_estimate(sample) / n) \n",
    "    x_mean = np.mean(sample)\n",
    "    return (x_mean - term, x_mean + term)\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def calculate_D_coef(n: int, p: float) -> float:\n",
    "    return math.sqrt(-(math.log((1 - p) / 2) / (2 * n))) - (1 / (6 * n))\n",
    "\n",
    "def expectation_confidence_interval_3(sample: Iterable,\n",
    "                                      confidence_probability: float,\n",
    "                                      shift: int = 0) -> tuple[float, float]:\n",
    "    n = len(sample)\n",
    "    sample = sorted(sample)\n",
    "    a, b = sample[shift], sample[-shift - 1]\n",
    "    term = (b - a) * calculate_D_coef(n, confidence_probability)\n",
    "    x_mean = np.mean(sample)\n",
    "    return (x_mean - term, x_mean + term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раннее рассмотренная функция вычисления доверительного интервала для дисперсии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_squared_confidence_interval(sample: Iterable, confidence_probability: float) -> tuple[float, float]:\n",
    "    deviation_estimate = sigma_squared_estimate(sample)\n",
    "    n = len(sample)\n",
    "    return (deviation_estimate * (n - 1) / chi_squared_quantile((1 + confidence_probability) / 2, n - 1), \n",
    "            deviation_estimate * (n - 1) / chi_squared_quantile((1 - confidence_probability) / 2, n - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Монте-Карло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_error_estimate(sample: Iterable,\n",
    "                               deltas: Iterable,\n",
    "                               iterations: int,\n",
    "                               func: Callable,\n",
    "                               *args) -> float | np.ndarray[float]:\n",
    "    y_0 = func(sample, *args)\n",
    "    if len(np.array(y_0).shape) > 0:\n",
    "        delta_y = [0.0] * len(y_0)\n",
    "    else:\n",
    "        delta_y = 0.0\n",
    "    rs = [sps.uniform(loc=-delta, scale=2 * delta) for delta in deltas]\n",
    "    for _ in tqdm(range(iterations)):\n",
    "        new_sample = [x + r.rvs() for x, r in zip(sample, rs)]\n",
    "        delta_y = np.maximum(delta_y, np.abs(np.subtract(func(new_sample, *args), y_0)))\n",
    "    return delta_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод линеаризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_derivatives(func: Callable, variables: Iterable, h: float, *params) -> float | np.ndarray[float]:\n",
    "    partial_derivatives = []\n",
    "    for i in range(len(variables)):\n",
    "        vars_plus_h, vars_minus_h = np.copy(variables), np.copy(variables)\n",
    "        vars_plus_h[i] += h\n",
    "        vars_minus_h[i] -= h\n",
    "        partial_derivatives.append(np.subtract(func(vars_plus_h, *params), func(vars_minus_h, *params)) / (2 * h))\n",
    "    return partial_derivatives\n",
    "\n",
    "def linearization_error_estimate(sample: Iterable,\n",
    "                                 deltas: Iterable,\n",
    "                                 func: Callable,\n",
    "                                 *args) -> float | np.ndarray[float]:\n",
    "    derivatives = partial_derivatives(func, sample, 1e-6, *args)\n",
    "    A = np.matrix(np.abs(derivatives))\n",
    "    if A.shape[0] == 1:\n",
    "        return np.sum(np.multiply(derivatives, deltas))\n",
    "    else:\n",
    "        return np.array(A.T @ deltas)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Крейновича"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_likelihood_parameters_estimation(sample: Iterable) -> tuple[float, float]:\n",
    "    \"\"\"Find MLE of Cauchy distribution parameters loc and scale.\"\"\"\n",
    "    def neglikelihood(params, data):\n",
    "        return -sps.cauchy.logpdf(data, loc=params[0], scale=params[1]).sum()\n",
    "    res = minimize(neglikelihood, [0, 0.00001], args=(sample))\n",
    "    return tuple(res.x)\n",
    "\n",
    "# without using the scipy.optimize.minimize method by solving the equation with the Newton method\n",
    "def maximum_likelihood_parameters_estimation_2(delta_y: Iterable) -> float:\n",
    "    def f(x: float, delta_y_squared: np.ndarray[float]) -> float:\n",
    "        return np.divide(x * x, np.add(x * x, delta_y_squared)).sum() - len(delta_y_squared) / 2\n",
    "        \n",
    "    delta_y_squared = np.multiply(delta_y, delta_y)\n",
    "    res = newton(f, 0.00001, args=(delta_y_squared,) )\n",
    "    return res\n",
    "\n",
    "def kreinovich_error_estimate(sample: Iterable,\n",
    "                              deltas: Iterable,\n",
    "                              N: int,\n",
    "                              func: Callable,\n",
    "                              *args) -> float | np.ndarray[float]:\n",
    "    k = 10 ** -2\n",
    "    y_0 = func(sample, *args)\n",
    "    delta_y = np.zeros((N, len(y_0)) if len(np.array(y_0).shape) > 0 else (N,))\n",
    "    rs = [sps.cauchy(loc=x_i, scale=k * delta_i) for x_i, delta_i in zip(sample, deltas)]\n",
    "    \n",
    "    for j in range(N):\n",
    "        new_sample = [r.rvs() for r in rs]\n",
    "        delta_y[j] = np.subtract(func(new_sample, *args), y_0)\n",
    "    if len(np.array(y_0).shape) > 0:\n",
    "        delta_y = np.array(np.matrix(delta_y).T)\n",
    "    else:\n",
    "        delta_y = [delta_y]\n",
    "\n",
    "    d = [maximum_likelihood_parameters_estimation_2(delta_y_i) for delta_y_i in delta_y]\n",
    "    return np.divide(d, k).astype(float) if len(d) > 1 else d[0] / k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все методы были реализованы так, чтобы они работали для любой функции $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ с любым количеством дополнительных параметров (в нашем случае это функции $\\mathbb{R}^n \\rightarrow \\mathbb{R}^2$, так как мы получаем две границы интервала по выборке размера $n$, при этом некоторым функциям вычисления границ нужно знать, например, дисперсию распределния выборки, которая не имеет погрешности)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTE_CARLO_ITERATIONS = 10 ** 4\n",
    "KREINOVICH_ITERATIONS = 300\n",
    "ERROR = 0.01\n",
    "Q = 0.95\n",
    "n = 100\n",
    "sigma_squared = {\"Uniform[-1, 1]\": 1 / 3,\n",
    "                 \"Norm(0, 1)\": 1,\n",
    "                 \"2xUniform[-1, 1]\": 2 / 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform[-1, 1]:\n",
      "Monte-Carlo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:28<00:00, 349.42it/s]\n",
      "100%|██████████| 10000/10000 [00:33<00:00, 298.47it/s]\n",
      "100%|██████████| 10000/10000 [00:28<00:00, 348.95it/s]\n",
      "100%|██████████| 10000/10000 [00:28<00:00, 354.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00132566 0.00132566] [0.00125077 0.00130159] [0.00323788 0.00330852] [0.00179024 0.0031339 ]\n",
      "Linearization:\n",
      "[0.00503728 0.00503728] [0.00506795 0.0050066 ] [0.00750805 0.00750707] [0.0052802  0.00924323]\n",
      "Kreinovich:\n",
      "[0.00486151 0.00486151] [0.00507097 0.00498534] [0.00760246 0.00724767] [0.0053538  0.00937208]\n",
      "\n",
      "\n",
      "Norm(0, 1):\n",
      "Monte-Carlo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:27<00:00, 365.23it/s]\n",
      "100%|██████████| 10000/10000 [00:28<00:00, 354.76it/s]\n",
      "100%|██████████| 10000/10000 [00:27<00:00, 361.61it/s]\n",
      "100%|██████████| 10000/10000 [00:27<00:00, 368.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00191207 0.00191207] [0.00206041 0.00176784] [0.00637968 0.00605098] [0.00424878 0.00743769]\n",
      "Linearization:\n",
      "[0.00660383 0.00660383] [0.00689657 0.0063111 ] [0.01172147 0.01160905] [0.01099735 0.01925137]\n",
      "Kreinovich:\n",
      "[0.00666844 0.00666844] [0.00686994 0.00626807] [0.01390438 0.014493  ] [0.01092274 0.01912076]\n",
      "\n",
      "\n",
      "2xUniform[-1, 1]:\n",
      "Monte-Carlo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:27<00:00, 367.87it/s]\n",
      "100%|██████████| 10000/10000 [00:27<00:00, 367.85it/s]\n",
      "100%|██████████| 10000/10000 [00:30<00:00, 332.54it/s]\n",
      "100%|██████████| 10000/10000 [00:35<00:00, 278.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00225075 0.00225075] [0.00234944 0.00244394] [0.00590617 0.00574992] [0.00407164 0.0071276 ]\n",
      "Linearization:\n",
      "[0.00732272 0.00732272] [0.00716269 0.00748274] [0.01191343 0.01191777] [0.01199601 0.02099957]\n",
      "Kreinovich:\n",
      "[0.00763952 0.00763952] [0.00660919 0.00700813] [0.01148424 0.01120536] [0.01194381 0.0209082 ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in DISTROS:\n",
    "    print(f\"{d}:\")\n",
    "    sample = generate_n_random_numbers(n, d)\n",
    "    deltas = np.abs(np.multiply(sample, ERROR))\n",
    "    print(\"Monte-Carlo:\")\n",
    "    error_1 = monte_carlo_error_estimate(sample, deltas, MONTE_CARLO_ITERATIONS, expectation_confidence_interval_1, Q, sigma_squared[d])\n",
    "    error_2 = monte_carlo_error_estimate(sample, deltas, MONTE_CARLO_ITERATIONS, expectation_confidence_interval_2, Q)\n",
    "    error_3 = monte_carlo_error_estimate(sample, deltas, MONTE_CARLO_ITERATIONS, expectation_confidence_interval_3, Q, 0)\n",
    "    error_4 = monte_carlo_error_estimate(sample, deltas, MONTE_CARLO_ITERATIONS, sigma_squared_confidence_interval, Q)\n",
    "    print(error_1, error_2, error_3, error_4)\n",
    "\n",
    "    print(\"Linearization:\")\n",
    "    error_1 = linearization_error_estimate(sample, deltas, expectation_confidence_interval_1, Q, sigma_squared[d])\n",
    "    error_2 = linearization_error_estimate(sample, deltas, expectation_confidence_interval_2, Q)\n",
    "    error_3 = linearization_error_estimate(sample, deltas, expectation_confidence_interval_3, Q, 0)\n",
    "    error_4 = linearization_error_estimate(sample, deltas, sigma_squared_confidence_interval, Q)\n",
    "    print(error_1, error_2, error_3, error_4)\n",
    "\n",
    "    print(\"Kreinovich:\")\n",
    "    error_1 = kreinovich_error_estimate(sample, deltas, KREINOVICH_ITERATIONS, expectation_confidence_interval_1, Q, sigma_squared[d])\n",
    "    error_2 = kreinovich_error_estimate(sample, deltas, KREINOVICH_ITERATIONS, expectation_confidence_interval_2, Q)\n",
    "    error_3 = kreinovich_error_estimate(sample, deltas, KREINOVICH_ITERATIONS, expectation_confidence_interval_3, Q, 0)\n",
    "    error_4 = kreinovich_error_estimate(sample, deltas, KREINOVICH_ITERATIONS, sigma_squared_confidence_interval, Q)\n",
    "    print(error_1, error_2, error_3, error_4)\n",
    "\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
