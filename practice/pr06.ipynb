{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections.abc import Iterable, Callable\n",
    "from utils import generate_n_random_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "\n",
    "Исследовать достаточной размера выборки для квантили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYTICAL_EXPECTATION = 0\n",
    "DISTROS = [\"Uniform[-1, 1]\", \"Norm(0, 1)\", \"2xUniform[-1, 1]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformSum:\n",
    "    def __init__(self, loc=0, scale=1) -> None:\n",
    "        self.r = sps.uniform(loc=loc, scale=scale)\n",
    "\n",
    "    def rvs(self, size: int) -> np.ndarray:\n",
    "        return np.add(self.r.rvs(size=size), self.r.rvs(size=size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR = {\"Uniform[-1, 1]\": sps.uniform(loc=-1, scale=2),\n",
    "             \"Norm(0, 1)\": sps.norm(loc=0, scale=1),\n",
    "             \"2xUniform[-1, 1]\": UniformSum(loc=-1, scale=2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache\n",
    "def norm_quantile(p, loc=0, scale=1):\n",
    "    return sps.norm.ppf(p, loc=loc, scale=scale)\n",
    "\n",
    "@lru_cache\n",
    "def student_quantile(p, n):\n",
    "    return sps.t.ppf(p, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция вычисления минимального достаточного размера выборки для вычисления доверительного интервала для $p\\cdot100$%-ой квантили с доверительной вероятностью $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sufficient_n_for_quantile(p: float, Q: float) -> int:\n",
    "    def lower_bound_on_sqrt_n(p, Q):\n",
    "        z = norm_quantile((Q + 1) / 2)\n",
    "        return (math.sqrt(1-p) * z + math.sqrt((1-p) * z * z + 4)) / (2 * math.sqrt(p))\n",
    "    return math.ceil(pow(max(lower_bound_on_sqrt_n(p, Q), lower_bound_on_sqrt_n(1 - p, Q)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция вычисления доверительного интервала для квантили с 4-ой практики (приближённая по локальной теореме Муавра-Лапласа)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_confidence_interval_approx(sample: list, confidence_probability: float, p=0.5) -> tuple:\n",
    "    sample = sorted(sample)\n",
    "    n = len(sample)\n",
    "    term = math.sqrt(n * p * (1 - p)) * norm_quantile((confidence_probability + 1) / 2)\n",
    "    m_1, m_2 = int(n * p - term), int(n * p + term)\n",
    "    return (sample[m_1] if m_1 >= 0 else -np.inf, sample[m_2] if m_2 <= n - 1 else np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sufficient n for 1%-quantile with Q=0.99 is 846\n",
      "OK! x_(1) = -0.997 and x_(n) = 1.000 are NOT in confidence interval [-0.991; -0.952] for ditribution Uniform[-1, 1]\n",
      "OK! x_(1) = -2.775 and x_(n) = 3.402 are NOT in confidence interval [-2.672; -2.034] for ditribution Norm(0, 1)\n",
      "OK! x_(1) = -1.889 and x_(n) = 1.953 are NOT in confidence interval [-1.828; -1.577] for ditribution 2xUniform[-1, 1]\n",
      "Sufficient n for 1%-quantile with Q=0.95 is 563\n",
      "OK! x_(1) = -1.000 and x_(n) = 0.998 are NOT in confidence interval [-0.999; -0.981] for ditribution Uniform[-1, 1]\n",
      "OK! x_(1) = -3.242 and x_(n) = 2.723 are NOT in confidence interval [-2.845; -2.105] for ditribution Norm(0, 1)\n",
      "OK! x_(1) = -1.872 and x_(n) = 1.922 are NOT in confidence interval [-1.849; -1.489] for ditribution 2xUniform[-1, 1]\n",
      "Sufficient n for 1%-quantile with Q=0.9 is 446\n",
      "OK! x_(1) = -0.998 and x_(n) = 0.995 are NOT in confidence interval [-0.995; -0.965] for ditribution Uniform[-1, 1]\n",
      "OK! x_(1) = -2.842 and x_(n) = 3.534 are NOT in confidence interval [-2.831; -2.130] for ditribution Norm(0, 1)\n",
      "OK! x_(1) = -1.926 and x_(n) = 1.781 are NOT in confidence interval [-1.853; -1.665] for ditribution 2xUniform[-1, 1]\n",
      "Sufficient n for 95%-quantile with Q=0.99 is 164\n",
      "OK! x_(1) = -0.988 and x_(n) = 0.974 are NOT in confidence interval [0.739; 0.964] for ditribution Uniform[-1, 1]\n",
      "OK! x_(1) = -2.511 and x_(n) = 2.490 are NOT in confidence interval [1.101; 2.400] for ditribution Norm(0, 1)\n",
      "OK! x_(1) = -1.764 and x_(n) = 1.892 are NOT in confidence interval [1.292; 1.767] for ditribution 2xUniform[-1, 1]\n",
      "Sufficient n for 95%-quantile with Q=0.95 is 110\n",
      "OK! x_(1) = -0.991 and x_(n) = 0.984 are NOT in confidence interval [0.815; 0.979] for ditribution Uniform[-1, 1]\n",
      "OK! x_(1) = -2.369 and x_(n) = 2.973 are NOT in confidence interval [1.209; 2.533] for ditribution Norm(0, 1)\n",
      "OK! x_(1) = -1.798 and x_(n) = 1.805 are NOT in confidence interval [1.311; 1.803] for ditribution 2xUniform[-1, 1]\n",
      "Sufficient n for 95%-quantile with Q=0.9 is 87\n",
      "OK! x_(1) = -0.991 and x_(n) = 0.991 are NOT in confidence interval [0.792; 0.967] for ditribution Uniform[-1, 1]\n",
      "OK! x_(1) = -2.518 and x_(n) = 1.878 are NOT in confidence interval [1.503; 1.870] for ditribution Norm(0, 1)\n",
      "OK! x_(1) = -1.574 and x_(n) = 1.774 are NOT in confidence interval [1.292; 1.644] for ditribution 2xUniform[-1, 1]\n"
     ]
    }
   ],
   "source": [
    "QS = [0.99, 0.95, 0.9]\n",
    "QUANTILES = [0.01, 0.95]\n",
    "for p in QUANTILES:\n",
    "    for Q in QS:\n",
    "        n = sufficient_n_for_quantile(p, Q)\n",
    "        print(f\"Sufficient n for {int(p*100)}%-quantile with Q={Q} is {n}\")\n",
    "        for d in DISTROS:\n",
    "            sample = GENERATOR[d].rvs(size=n)\n",
    "            a, b = quantile_confidence_interval_approx(sample, Q, p)\n",
    "            x_1, x_n = min(sample), max(sample)\n",
    "            if a <= x_1 <= b:\n",
    "                print(f\"ERROR. x_(1) = {x_1:.3f} is in confidence interval [{a:.3f}; {b:.3f}] for ditribution {d}\")\n",
    "            elif a <= x_n <= b:\n",
    "                print(f\"ERROR. x_(n) = {x_n:.3f} is in confidence interval [{a:.3f}; {b:.3f}] for ditribution {d}\")\n",
    "            else:\n",
    "                print(f\"OK! x_(1) = {x_1:.3f} and x_(n) = {x_n:.3f} are NOT in confidence interval [{a:.3f}; {b:.3f}] for ditribution {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Реализуем методы для оценки погрешности, наследуемой результатами статистической обработки данных от неопределенности исходных обрабатываемых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раннее рассмотренные функции подсчёта доверительного интервала для матождиания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_confidence_interval_1(sample: Iterable,\n",
    "                                      confidence_probability: float,\n",
    "                                      sigma_squared: float) -> tuple[float, float]:\n",
    "    n = len(sample)\n",
    "    term = norm_quantile((1 + confidence_probability) / 2) * math.sqrt(sigma_squared / n)\n",
    "    x_mean = np.mean(sample)\n",
    "    return (x_mean - term, x_mean + term)\n",
    "\n",
    "\n",
    "def estimate_sigma(sample: Iterable) -> float:\n",
    "    x_mean = np.mean(sample)\n",
    "    return math.sqrt(sum([pow(xi - x_mean, 2) for xi in sample]) / (len(sample) - 1))\n",
    "\n",
    "def expectation_confidence_interval_2(sample: Iterable,\n",
    "                                      confidence_probability: float) -> tuple[float, float]:\n",
    "    n = len(sample)\n",
    "    term = student_quantile((1 + confidence_probability) / 2, n - 1) * estimate_sigma(sample) / math.sqrt(n) \n",
    "    x_mean = np.mean(sample)\n",
    "    return (x_mean - term, x_mean + term)\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def calculate_D_coef(n: int, p: float) -> float:\n",
    "    return math.sqrt(-(math.log((1 - p) / 2) / (2 * n))) - (1 / (6 * n))\n",
    "\n",
    "def expectation_confidence_interval_3(sample: Iterable,\n",
    "                                      confidence_probability: float,\n",
    "                                      shift: int = 0) -> tuple[float, float]:\n",
    "    n = len(sample)\n",
    "    sample = sorted(sample)\n",
    "    a, b = sample[shift], sample[-shift - 1]\n",
    "    term = (b - a) * calculate_D_coef(n, confidence_probability)\n",
    "    x_mean = np.mean(sample)\n",
    "    return (x_mean - term, x_mean + term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Монте-Карло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_error_estimate(sample: Iterable,\n",
    "                               deltas: Iterable,\n",
    "                               iterations: int,\n",
    "                               func: Callable, *args) -> float | np.ndarray[float]:\n",
    "    y_0 = func(sample, *args)\n",
    "    if len(np.array(y_0).shape) > 0:\n",
    "        delta_y = [0.0] * len(y_0)\n",
    "    else:\n",
    "        delta_y = 0.0\n",
    "    rs = [sps.uniform(loc=-delta, scale=2 * delta) for delta in deltas]\n",
    "    for _ in tqdm(range(iterations)):\n",
    "        new_sample = [x + r.rvs() for x, r in zip(sample, rs)]\n",
    "        delta_y = np.maximum(delta_y, np.abs(np.subtract(func(new_sample, *args), y_0)))\n",
    "    return delta_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод линеаризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_derivatives(func: Callable, variables: Iterable, h: float, *params) -> float | np.ndarray[float]:\n",
    "    partial_derivatives = []\n",
    "    for i in range(len(variables)):\n",
    "        vars_plus_h, vars_minus_h = np.copy(variables), np.copy(variables)\n",
    "        vars_plus_h[i] += h\n",
    "        vars_minus_h[i] -= h\n",
    "        partial_derivatives.append(np.subtract(func(vars_plus_h, *params), func(vars_minus_h, *params)) / (2 * h))\n",
    "    return partial_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearization_error_estimate(sample: Iterable,\n",
    "                                 deltas: Iterable,\n",
    "                                 func: Callable, *args) -> float | np.ndarray[float]:\n",
    "    derivatives = partial_derivatives(func, sample, 1e-6, *args)\n",
    "    A = np.matrix(np.abs(derivatives))\n",
    "    if A.shape[0] == 1:\n",
    "        return np.sum(np.multiply(derivatives, deltas))\n",
    "    else:\n",
    "        return np.array(A.T @ deltas)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оба метода были реализованы так, чтобы работать для любой функции $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ с любым количеством дополнительных параметров (в нашем случае это функции $\\mathbb{R}^n \\rightarrow \\mathbb{R}^2$, так как мы получаем две границы интервала по выборке размера $n$, при этом некоторым функциям вычисления границ нужно знать, например, дисперсию распределния выборки, которая не имеет погрешности)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTE_CARLO_ITERATIONS = 10 ** 4\n",
    "ERROR = 0.01\n",
    "Q = 0.95\n",
    "n = 100\n",
    "sigma_squared = {\"Uniform[-1, 1]\": 1 / 3,\n",
    "                 \"Norm(0, 1)\": 1,\n",
    "                 \"2xUniform[-1, 1]\": 2 / 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform[-1, 1]:\n",
      "Monte-Carlo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:27<00:00, 366.13it/s]\n",
      "100%|██████████| 10000/10000 [00:27<00:00, 368.75it/s]\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 378.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00116094 0.00116094] [0.00134225 0.00133616] [0.00356786 0.00309058]\n",
      "Linearization:\n",
      "[0.00483925 0.00483925] [0.0048758 0.0048027] [0.00722035 0.00720896]\n",
      "\n",
      "\n",
      "Norm(0, 1):\n",
      "Monte-Carlo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 387.48it/s]\n",
      "100%|██████████| 10000/10000 [00:27<00:00, 369.86it/s]\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 381.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00222193 0.00222193] [0.00217457 0.00237288] [0.00767585 0.00739322]\n",
      "Linearization:\n",
      "[0.00792337 0.00792337] [0.00786326 0.00798348] [0.01399866 0.0141309 ]\n",
      "\n",
      "\n",
      "2xUniform[-1, 1]:\n",
      "Monte-Carlo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 391.71it/s]\n",
      "100%|██████████| 10000/10000 [00:27<00:00, 369.30it/s]\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 375.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0014785 0.0014785] [0.00156029 0.00188027] [0.00567697 0.00575179]\n",
      "Linearization:\n",
      "[0.00580088 0.00580088] [0.00566803 0.00593374] [0.01032603 0.01033735]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for d in DISTROS:\n",
    "    print(f\"{d}:\")\n",
    "    sample = generate_n_random_numbers(100, d)\n",
    "    deltas = np.abs(np.multiply(sample, ERROR))\n",
    "    print(\"Monte-Carlo:\")\n",
    "    error_1 = monte_carlo_error_estimate(sample, deltas, MONTE_CARLO_ITERATIONS, expectation_confidence_interval_1, Q, sigma_squared[d])\n",
    "    error_2 = monte_carlo_error_estimate(sample, deltas, MONTE_CARLO_ITERATIONS, expectation_confidence_interval_2, Q)\n",
    "    error_3 = monte_carlo_error_estimate(sample, deltas, MONTE_CARLO_ITERATIONS, expectation_confidence_interval_3, Q, 0)\n",
    "    print(error_1, error_2, error_3)\n",
    "\n",
    "    print(\"Linearization:\")\n",
    "    error_1 = linearization_error_estimate(sample, deltas, expectation_confidence_interval_1, Q, sigma_squared[d])\n",
    "    error_2 = linearization_error_estimate(sample, deltas, expectation_confidence_interval_2, Q)\n",
    "    error_3 = linearization_error_estimate(sample, deltas, expectation_confidence_interval_3, Q, 0)\n",
    "    print(error_1, error_2, error_3)\n",
    "\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
